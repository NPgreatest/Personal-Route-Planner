{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import tqdm\n",
    "def connect_to_database():\n",
    "    \"\"\"连接到数据库并返回连接对象\"\"\"\n",
    "    connection = mysql.connector.connect(\n",
    "        host='127.0.0.1',\n",
    "        user='root',\n",
    "        password='root',\n",
    "        database='route_planner'\n",
    "    )\n",
    "    return connection\n",
    "connection = connect_to_database()\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO sites (sid, sname, description, pic, website) VALUES (%s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "with open('shanghai.csv', mode='r', encoding='gbk') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip header\n",
    "    for row in csv_reader:\n",
    "        sid = int(row[0])  # 假设CSV文件的第一列是sid\n",
    "        sname = row[1]  # 假设CSV文件的第二列是sname\n",
    "        description = row[10]  # 假设CSV文件的第三列是description\n",
    "        # 生成图片URL，假设图片按sid命名\n",
    "        pic = f\"http://localhost:8080/images/{sid}\"\n",
    "        website = None  # website为空\n",
    "        # 插入数据\n",
    "        cursor.execute(insert_query, (sid, sname, description, pic, website))\n",
    "\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "insert_query = \"\"\"\n",
    "INSERT INTO sites_tags (sid,tagid) VALUES (%s, %s)\n",
    "\"\"\"\n",
    "\n",
    "sites_tags_data = []\n",
    "with open('shanghai.csv', mode='r', encoding='gbk') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip the header row\n",
    "    for row in csv_reader:\n",
    "        sid = int(row[0])  # Assuming the first column of the CSV is 'sid'\n",
    "        tagids_str = row[11]  # Assuming the eleventh column of the CSV is 'tagid'\n",
    "        tagids = tagids_str.split(',')  # Split the string by comma\n",
    "        for tagid in tagids:\n",
    "            if tagid.strip().isdigit():  # Ensure that tagid is a digit after stripping whitespace\n",
    "                sites_tags_data.append((sid, int(tagid.strip())))\n",
    "\n",
    "for item in sites_tags_data:\n",
    "    cursor.execute(insert_query, (str(item[0]) ,str(item[1])))\n",
    "\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tag_names= [\"User\",\"宗教场所\",\"度假区\",\"海滩\",\"公园/森林公园\",\"剧院/表演场所\",\"博物馆/展览馆\",\"购物中心/商场\",\"动物园/水族馆\",\"餐厅/美食\",\"酒吧/夜生活\",\"本地服务/体验活动\",\"汉堡/披萨店（需调整或删除）\",\"酒店/住宿\",\"果汁吧/甜品店\",\"艺术画廊/艺术空间\",\"舞蹈俱乐部/娱乐场所\",\"游泳池\",\"健身房/运动中心\",\"面包店/糕点店（需调整或删除）\",\"美容&Spa\",\"咖啡厅（需调整或删除）\",\"观景点\",\"纪念碑/历史遗址\",\"花园/自然景观\"]\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO tags (tagid,name) VALUES (%s, %s)\n",
    "\"\"\"\n",
    "for idx,item in  enumerate(tag_names):\n",
    "    if idx==0:\n",
    "        continue\n",
    "    cursor.execute(insert_query,(str(idx),item))\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "insert_query = \"\"\"\n",
    "INSERT INTO rating (name,sid,rating) VALUES (%s, %s,%s)\n",
    "\"\"\"\n",
    "\n",
    "with open('user_rating.csv', mode='r', encoding='gbk') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip the header row\n",
    "\n",
    "    for row in csv_reader:\n",
    "        uName = row[0]\n",
    "        sid=int(row[1])\n",
    "        value = int(row[2])\n",
    "        cursor.execute(insert_query, (uName,sid,value))\n",
    "\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting details: 100%|██████████| 432/432 [08:41<00:00,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "insert_query = \"\"\"\n",
    "INSERT INTO activity (sid,detail) VALUES (%s,%s)\n",
    "\"\"\"\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "client = OpenAI(\n",
    "    base_url = 'https://api.kwwai.top/v1',\n",
    "    api_key = 'sk-AYP9eKTcCHOqFrneC4E358Af7f12489dA601A5F012099fD1'\n",
    ")\n",
    "\n",
    "def try_get_detail(name):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0.9,\n",
    "        n=5,\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"请根据景点名称:{name}生成一个适合在这个景点进行的班级活动，字数控制在4-10个之间,直接输出班级活动内容。\\n所以说整体只用输出4-10个中文汉字即可\",\n",
    "        },\n",
    "    ],\n",
    "    )\n",
    "    return response\n",
    "\n",
    "with open('shanghai.csv', mode='r', encoding='gbk') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip the header row\n",
    "\n",
    "    for row in tqdm(csv_reader,total=432,desc='getting details'):\n",
    "        name = row[1]\n",
    "        sid = int(row[0])\n",
    "        detail = try_get_detail(name)\n",
    "        for i in range(5):\n",
    "            cursor.execute(insert_query, (sid,detail.choices[i].message.content))\n",
    "\n",
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "connection.commit()\n",
    "cursor.close()\n",
    "connection.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "getting details: 100%|██████████| 432/432 [02:34<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import urllib\n",
    "import json\n",
    "import socket\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "# 设置超时\n",
    "import time\n",
    "\n",
    "import random\n",
    "\n",
    "timeout = 5\n",
    "socket.setdefaulttimeout(timeout)\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "\n",
    "class Crawler:\n",
    "    # 睡眠时长\n",
    "    __time_sleep = 0.1\n",
    "    __amount = 0\n",
    "    __start_amount = 0\n",
    "    __counter = 0\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:23.0) Gecko/20100101 Firefox/23.0', 'Cookie': ''}\n",
    "    __per_page = 30\n",
    "\n",
    "    # 获取图片url内容等\n",
    "    # t 下载图片时间间隔\n",
    "    def __init__(self, t=0.1):\n",
    "        self.time_sleep = t\n",
    "\n",
    "    # 获取后缀名\n",
    "    @staticmethod\n",
    "    def get_suffix(name):\n",
    "        m = re.search(r'\\.[^\\.]*$', name)\n",
    "        if m.group(0) and len(m.group(0)) <= 5:\n",
    "            return m.group(0)\n",
    "        else:\n",
    "            return '.jpeg'\n",
    "\n",
    "    @staticmethod\n",
    "    def handle_baidu_cookie(original_cookie, cookies):\n",
    "        if not cookies:\n",
    "            return original_cookie\n",
    "        result = original_cookie\n",
    "        for cookie in cookies:\n",
    "            result += cookie.split(';')[0] + ';'\n",
    "        result.rstrip(';')\n",
    "        return result\n",
    "\n",
    "    # 开始获取\n",
    "    def get_images(self, word):\n",
    "        search = urllib.parse.quote(word)\n",
    "        pn = self.__start_amount\n",
    "        image_urls = []\n",
    "        while pn < self.__amount:\n",
    "            url = 'https://image.baidu.com/search/acjson?tn=resultjson_com&ipn=rj&ct=201326592&is=&fp=result&queryWord=%s&cl=2&lm=-1&ie=utf-8&oe=utf-8&adpicid=&st=-1&z=&ic=&hd=&latest=&copyright=&word=%s&s=&se=&tab=&width=&height=&face=0&istype=2&qc=&nc=1&fr=&expermode=&force=&pn=%s&rn=%d&gsm=1e&1594447993172=' % (\n",
    "                search, search, str(pn), self.__per_page)\n",
    "            try:\n",
    "                time.sleep(self.time_sleep)\n",
    "                req = urllib.request.Request(url=url, headers=self.headers)\n",
    "                page = urllib.request.urlopen(req)\n",
    "                self.headers['Cookie'] = self.handle_baidu_cookie(self.headers['Cookie'],\n",
    "                                                                page.info().get_all('Set-Cookie'))\n",
    "                rsp = page.read()\n",
    "                page.close()\n",
    "            except UnicodeDecodeError as e:\n",
    "                print(e)\n",
    "                print('-----UnicodeDecodeErrorurl:', url)\n",
    "            except urllib.error.URLError as e:\n",
    "                print(e)\n",
    "                print(\"-----urlErrorurl:\", url)\n",
    "            except socket.timeout as e:\n",
    "                print(e)\n",
    "                print(\"-----socket timout:\", url)\n",
    "            else:\n",
    "                rsp_data = json.loads(rsp, strict=False, object_hook=lambda d: {k: urllib.parse.unquote(v) if isinstance(v, str) else v for k, v in d.items()})\n",
    "                if 'data' not in rsp_data:\n",
    "                    continue\n",
    "                else:\n",
    "                    for image_info in rsp_data['data']:\n",
    "                        if 'thumbURL' in image_info:\n",
    "                            thumb_url = image_info['thumbURL']\n",
    "                            image_urls.append(thumb_url)\n",
    "                pn += self.__per_page\n",
    "                return image_urls\n",
    "\n",
    "    def start(self, word):\n",
    "        self.__per_page = 30\n",
    "        self.__start_amount = 0\n",
    "        self.__amount = self.__per_page\n",
    "        return self.get_images(word)\n",
    "\n",
    "\n",
    "import urllib.request\n",
    "with open('shanghai.csv', mode='r', encoding='gbk') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip the header row\n",
    "    idx=1\n",
    "    for row in tqdm(csv_reader,total=432,desc='getting details'):\n",
    "        if idx < 406:\n",
    "            idx+=1\n",
    "            continue\n",
    "        word = row[1]\n",
    "\n",
    "        crawler = Crawler(0.1)\n",
    "        image_urls = crawler.start(word)\n",
    "        if image_urls:\n",
    "            image_url = random.choice(image_urls)\n",
    "        urllib.request.urlretrieve(image_url, './pic/'+str(idx)+'.jpg')\n",
    "        idx+=1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}